{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5377e29e",
   "metadata": {},
   "source": [
    "# WEEK4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9300070",
   "metadata": {},
   "source": [
    "## Taylor series and linearisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce1d2d",
   "metadata": {},
   "source": [
    "The Taylor series is a method for re-expressing functions as polynomial series. This approach is the rational behind the use of simple linear approximations to complicated functions. In this module, we will derive the formal expression for the univariate Taylor series and discuss some important consequences of this result relevant to machine learning. Finally, we will discuss the multivariate case and see how the Jacobian and the Hessian come in to play.\n",
    "\n",
    "Goals:\n",
    "\n",
    "1. Recognise power series approximations to functions\n",
    "\n",
    "2. Interpret the behaviour of power series approximations for ill-behaved functions\n",
    "\n",
    "3. Explain the meaning and relevance of linearisation\n",
    "\n",
    "4. Select appropriate representation of multivariate approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af368af",
   "metadata": {},
   "source": [
    "## Taylor series for approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d52223",
   "metadata": {},
   "source": [
    "**Tylar series** are also known as **power series**. This is because they composed of coefficients in front of increasing powers of X. So we can write a simple generalised expression for a power series as g of X:\n",
    "\n",
    "$$g(x)=a+bx+cx^2+dx^3+...$$\n",
    "\n",
    "Starting from just a single term, we call these short expressions the zeroth, first, second and third order approximations:\n",
    "\n",
    "$$g_0(x)=a$$\n",
    "\n",
    "$$g_1(x)=a+bx$$\n",
    "\n",
    "$$g_2(x)=a+bx+cx^2$$\n",
    "\n",
    "$$g_3(x)=a+bx+cx^2+dx^3$$\n",
    "\n",
    "$$...$$\n",
    "\n",
    "Collectively, these short sections of the series are called **Truncated series**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48dda29",
   "metadata": {},
   "source": [
    "$$e^x=1+x+\\frac{x^2}{2}+\\frac{x^3}{6}+\\frac{x^4}{24}+...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a41fa2",
   "metadata": {},
   "source": [
    "What the Taylor series method tells us is that if we know everything about the function at some point, whereby everything, I mean the functions value, its first derivative, second derivative, third derivative etc. Then we can use this information to reconstruct the function everywhere else. However, this is only true for a certain type of function that we call well behaved, which means functions that are continuous and that you can differentiate as many times as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa399e",
   "metadata": {},
   "source": [
    "$$g_0(x)=f(0)$$\n",
    "\n",
    "At the point of $x=0$:\n",
    "\n",
    "And for $g_1(x)=ax+b$:\n",
    "\n",
    "$$ax+b=f(0)$$\n",
    "\n",
    "$$a=f'(0)$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$g_1(x)=f(0)+f'(0)x$$\n",
    "\n",
    "And for $g_2(x)=ax^2+bx+c$:\n",
    "\n",
    "$$ax^2+bx+c=f(0)$$\n",
    "\n",
    "$$2ax+b=f'(0)$$\n",
    "\n",
    "$$2a=f''(0)$$\n",
    "\n",
    "so: $a=\\frac{f''(0)}{2}$, $b=f'(0)$, $c=f(0)$\n",
    "\n",
    "So:\n",
    "\n",
    "$$g_2(x)=f(0)+f'(0)x+\\frac{1}{2}f''(0)x^2$$\n",
    "\n",
    "And for $g_3(x)=ax^3+bx^2+cx+d$:\n",
    "\n",
    "$$ax^3+bx^2+cx+d=f(0)$$\n",
    "\n",
    "$$3ax^2+2bx+c=f'(0)$$\n",
    "\n",
    "$$6ax+2b=f''(0)$$\n",
    "\n",
    "$$6a=f^{(3)}(0)$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$g_3(x)=f(0)+f'(0)x+\\frac{1}{2}f''(0)x^2+\\frac{1}{6}f^{(3)}(0)x^3$$\n",
    "\n",
    "$$g_4(x)=f(0)+f'(0)x+\\frac{1}{2}f''(0)x^2+\\frac{1}{6}f^{(3)}(0)x^3+\\frac{1}{24}f^{(4)}(0)x^4$$\n",
    ">where $2=1x2$, $6=1x2x3$, $24=1x2x3x4$(4!, four factorial)\n",
    "\n",
    "In fact all the terms can be thought of as having a factorial in front of them:\n",
    "$$g_4(x)=\\frac{f^{(0)}(0)}{0!}+\\frac{f^{(1)}(0)x}{1!}+\\frac{f^{(2)}(0)x^2}{2!}+\\frac{f^{(3)}(0)x^3}{3!}+\\frac{f^{(4)}(0)x^4}{4!}$$\n",
    ">where $2=1x2$, $6=1x2x3$, $24=1x2x3x4$(4!, four factorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd0e02",
   "metadata": {},
   "source": [
    "**The approximation functions to f(x) at the point 0**\n",
    "\n",
    "$$g_0(x)=f(0)$$\n",
    "\n",
    "$$g_1(x)=f(0)+f'(0)x$$\n",
    "\n",
    "$$g_2(x)=f(0)+f'(0)x+\\frac{1}{2}f''(0)x^2$$\n",
    "\n",
    "$$g_3(x)=f(0)+f'(0)x+\\frac{1}{2}f''(0)x^2+\\frac{1}{6}f^{(3)}(0)x^3$$\n",
    "\n",
    "$$g_4(x)=f(0)+f'(0)x+\\frac{1}{2}f''(0)x^2+\\frac{1}{6}f^{(3)}(0)x^3+\\frac{1}{24}f^{(4)}(0)x^4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbf168",
   "metadata": {},
   "source": [
    "Therefore, the complete power series can be written as follows:\n",
    "$$g(x)=\\Sigma_{n=0}^{\\infty}{\\frac{1}{n!}f^{(n)}(0)x^n}=\\Sigma_{n=0}^{\\infty}{\\frac{f^{(n)}(0)x^n}{n!}}$$\n",
    "> **Maclaurin Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038451f1",
   "metadata": {},
   "source": [
    "And imgaine if we have a function $f$, at the point $x=p$, we will have $f(p)$. The gradient of the point is $f'(p)$.\n",
    "\n",
    "So we will have the approximation at the point $x=p$: $$y=mx+c$$\n",
    "\n",
    "And because $$y=f'(p)x+c$$\n",
    "\n",
    "there is $$f(p)=f'(p)p+c$$\n",
    "\n",
    "So $$c=f(p)-f'(p)p$$\n",
    "\n",
    "So we will have $$y=f'(p)x+f(p)-f'(p)p=f'(p)(x-p)+f(p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973554e",
   "metadata": {},
   "source": [
    "**THe approximation functions to f(x) at the point p**\n",
    "\n",
    "$$g_0(x)=f(p)$$\n",
    "\n",
    "$$g_1(x)=f(p)+f'(p)(x-p)$$\n",
    "\n",
    "$$g_2(x)=f(p)+f'(p)(x-p)+\\frac{1}{2}f''(p)(x-p)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c811727",
   "metadata": {},
   "source": [
    "**Taylor Series**\n",
    "\n",
    "$$g(x)=\\Sigma_{n=0}^{\\infty}{\\frac{f^{(n)}(p)}{n!}(x-p)^n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3652709",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1e691",
   "metadata": {},
   "source": [
    "**To build a Maclaurin series expansion of the cosine function**\n",
    "\n",
    "$$f(x)=cos(x)$$\n",
    "\n",
    "Now we bring back general for the Maclaurin series:\n",
    "\n",
    "$$cos(x)=1-\\frac{x^2}{2}+\\frac{x^4}{24}-\\frac{x^6}{720}+...$$\n",
    "\n",
    "And we can build a neat summation notation which fully describes this series without having to write all the terms:\n",
    "\n",
    "$$cos(x)=\\Sigma_{n=0}^{\\infty}\\frac{(-1)^n}{(2n)!}x^{2n}$$\n",
    "\n",
    "By the time we get our 16th order approximation, we've pretty much nailed the region shown in our graph here. Although just outside of these axes, the function would also be growing hugely positive. So you must always be careful when handling series approximations that you know the **domain in which it's acceptable**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a2aed",
   "metadata": {},
   "source": [
    "**To build a Maclaurin of the function $f(x)=\\frac{1}{x}$**\n",
    "\n",
    "This is absolutely not a well behaved function. In fact, it's so badly behaved that when we even try and build the zeroth order approximation, we immediately run into problems. Because we have to perform the operation 1 divided by 0 which is not defined $f(0)=\\frac{1}{0}=NaN$.\n",
    ">NaN stands for \"not a number\"\n",
    "\n",
    "$$g(x)=\\Sigma_{n=0}^{\\infty}\\frac{f^{(0)}(0)}{n!}x^n$$\n",
    "\n",
    "So we have to move to $x=1$ and use taylor series:\n",
    "\n",
    "$$g(x)=\\Sigma_{n=0}^{\\infty}\\frac{f^{(n)}(p)}{n!}(x-p)^n$$\n",
    "\n",
    "But then we will have other problems:\n",
    "\n",
    "1. the approximations ignore the asymptote, going straight across it. And furthermore, the region of the function where x is less than 0 is not described at all by the approximations. \n",
    "2. although the function is gradually improving for larger values of x, you can see the tail wildly flailing around as the sign of each additional term flips from positive to negative and back again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49c2f7",
   "metadata": {},
   "source": [
    "## Multivariable Taylor Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0da86f",
   "metadata": {},
   "source": [
    "So as we've already seen, we can build up a sequence of gradually improving approximations to functions by adding higher power terms. \n",
    "\n",
    "Now recall \"rise and run\":\n",
    "\n",
    "$$f(x+\\Delta{x})=\\Sigma_{n=0}^{\\infty}{\\frac{f^{(n)}(x)}{n!}\\Delta{x^n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182faa8",
   "metadata": {},
   "source": [
    "This means that if we can say that delta x is a small number, then $\\Delta{x}$ squared must be a really small number, and similarly, **$\\Delta{x}$ cubed must be a ridiculously small number**. So we can now rewrite our first order approximation to include an error term, which we just say is on the order of delta x squared, or equally that it is second order accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797057d6",
   "metadata": {},
   "source": [
    "$$g_1(x+\\Delta{x})=f(x)+f'(x)(\\Delta{x}))$$\n",
    "\n",
    "$$f(x+\\Delta{x})=f(x)+f'(x)\\Delta{x}+O(\\Delta{x^2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811dfe26",
   "metadata": {},
   "source": [
    "We've taken some potentially very nasty function and just approximated it with a straight line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d2093",
   "metadata": {},
   "source": [
    "$$f'(x)=\\frac{f(x+\\Delta{x})-f(x)}{\\Delta{x}}+O(\\Delta{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4855741",
   "metadata": {},
   "source": [
    "### Multivariate Taylor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cddc15",
   "metadata": {},
   "source": [
    "We start with 2-D: $f(x+\\Delta{x},y+\\Delta{y})=???$\n",
    "\n",
    "$$f(x+\\Delta{x},y+\\Delta{y})=f(x,y)+(\\partial{_x}f(x,y)\\Delta{x}+\\partial{_y}f(x,y)\\Delta{y})+\\frac{1}{2}(\\partial{_{xx}}f(x,y)\\Delta{x^2}+2\\partial{_{xy}}f(x,y)\\Delta{x}\\Delta{y}+\\partial{_{yy}}f(x,y)\\Delta{y^2})+...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6c8ab",
   "metadata": {},
   "source": [
    "$$\\partial{_y}f(x,y)\\Delta{y})+\\frac{1}{2}(\\partial{_{xx}}f(x,y)\\Delta{x^2}=\\begin{bmatrix}\\partial{_x}f(x,y),\\partial{_y}(x,y)\\end{bmatrix}\\begin{bmatrix}\\Delta{x}\\\\\\Delta{y}\\end{bmatrix}=J_f\\Delta{\\mathbf{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f57ba2",
   "metadata": {},
   "source": [
    "It's the sum of the product of the first derivatives with the step sizes, but hopefully this will remind you of the discussion our Jacobian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b8b11",
   "metadata": {},
   "source": [
    "$$\\frac{1}{2}(\\partial{_{xx}}f(x,y)\\Delta{x^2}+2\\partial{_{xy}}f(x,y)\\Delta{x}\\Delta{y}+\\partial{_{yy}}f(x,y)\\Delta{y^2})=\\frac{1}{2}\\begin{bmatrix}\\Delta{x},\\Delta{y}\\end{bmatrix}\\begin{bmatrix}\\partial{_{xx}}f(x,y)&\\partial{_{xy}}f(x,y)\\\\\\partial{_{yx}}f(x,y)&\\partial{_{yy}}f(x,y)\\end{bmatrix}=\\frac{1}{2}\\Delta{\\mathbf{x^t}}H_f\\Delta{\\mathbf{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5a6ed",
   "metadata": {},
   "source": [
    "Finally, if we look at the second order term in the same way and notice that these second derivatives can be collected into a matrix, which we've previously defined as our Hessian. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f88c9",
   "metadata": {},
   "source": [
    "So we now have a nice compact expression for the second order multivariate Taylor series expansion, which brings together so much of our calculus and linear algebra skills, and makes use of the Jacobian and Hessian concepts which we defined earlier in the course. \n",
    "\n",
    "$$f(\\mathbf{x}+\\Delta{\\mathbf{x}})=f(\\mathbf{x})+J_f\\Delta{\\mathbf{x}}+\\frac{1}{2}\\Delta{x^t}H_f\\Delta{\\mathbf{x}}+...$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
